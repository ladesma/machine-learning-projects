{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "redneuronaltesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU_QWhAfR5ph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "outputId": "93f91f89-289a-4570-b11c-7db1aa8ad862"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# TensorFlow y tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "# Librerias de ayuda\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) \n",
        "data = pd.read_csv('taiwan.csv.csv')\n",
        "corr_data = data.corr()\n",
        "high_corr = ~(corr_data.mask(np.eye(len(corr_data ), dtype=bool)).abs() > 0.5).any()\n",
        "high_corr\n",
        "\n",
        "corr_data = corr_data.loc[high_corr,high_corr]\n",
        "print(corr_data.columns)\n",
        "target = data['Bankrupt?']\n",
        "del data['Bankrupt?']\n",
        "dato = data[:1]\n",
        "sns.set_style('white');\n",
        "sns.set_context(context='notebook',font_scale=1.2)\n",
        "sns.countplot(x=target);\n",
        "plt.title('Target variable unbalanced');\n",
        "SMOTE_oversample = SMOTE()\n",
        "data,target = SMOTE_oversample.fit_resample(data,target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=42)\n",
        "\"\"\"\n",
        "sns.set_style('white');\n",
        "sns.set_context(context='notebook',font_scale=1.2)\n",
        "sns.countplot(x=y_train);\n",
        "plt.title('Target variable balanced');\n",
        "\"\"\"\n",
        "std_slc =  StandardScaler()\n",
        "std_slc.fit(X_train)\n",
        "X_train_std = std_slc.transform(X_train)\n",
        "X_test_std = std_slc.transform(X_test)\n",
        "pca = PCA(n_components=93)# adjust yourself\n",
        "pca.fit(X_train_std)\n",
        "X_t_train_std = pca.transform(X_train_std)\n",
        "X_t_test_std = pca.transform(X_test_std)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Bankrupt?', ' Operating Expense Rate',\n",
            "       ' Research and development expense rate',\n",
            "       ' Interest-bearing debt interest rate', ' Tax rate (A)',\n",
            "       ' Revenue Per Share (Yuan Â¥)',\n",
            "       ' Realized Sales Gross Profit Growth Rate',\n",
            "       ' Continuous Net Profit Growth Rate', ' Total Asset Growth Rate',\n",
            "       ' Net Value Growth Rate', ' Total Asset Return Growth Rate Ratio',\n",
            "       ' Current Ratio', ' Quick Ratio', ' Interest Expense Ratio',\n",
            "       ' Total debt/Total net worth', ' Long-term fund suitability ratio (A)',\n",
            "       ' Accounts Receivable Turnover', ' Average Collection Days',\n",
            "       ' Inventory Turnover Rate (times)', ' Fixed Assets Turnover Frequency',\n",
            "       ' Revenue per person', ' Operating profit per person',\n",
            "       ' Allocation rate per person', ' Quick Assets/Current Liability',\n",
            "       ' Cash/Current Liability', ' Inventory/Working Capital',\n",
            "       ' Inventory/Current Liability',\n",
            "       ' Long-term Liability to Current Assets', ' Total income/Total expense',\n",
            "       ' Current Asset Turnover Rate', ' Quick Asset Turnover Rate',\n",
            "       ' Cash Turnover Rate', ' Fixed Assets to Assets',\n",
            "       ' Liability-Assets Flag', ' Total assets to GNP price',\n",
            "       ' No-credit Interval', ' Degree of Financial Leverage (DFL)',\n",
            "       ' Interest Coverage Ratio (Interest expense to EBIT)',\n",
            "       ' Net Income Flag'],\n",
            "      dtype='object')\n",
            "[0 1 0 ... 0 1 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3301goER79G"
      },
      "source": [
        "early_stop =  EarlyStopping(monitor='loss',mode='max', verbose=1, patience=30,restore_best_weights=True)\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(100 , activation='relu', input_shape=[93]),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dropout(0.10),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY7abjQJVgee",
        "outputId": "abfe2aa4-9c26-42b8-8293-3e1358b7f95e"
      },
      "source": [
        "history = model.fit(\n",
        "    X_t_train_std, \n",
        "    y_train, \n",
        "    epochs=100, \n",
        "    batch_size=10,  \n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1056/1056 [==============================] - 3s 2ms/step - loss: 0.2679 - accuracy: 0.8903\n",
            "Epoch 2/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0988 - accuracy: 0.9664\n",
            "Epoch 3/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0556 - accuracy: 0.9841\n",
            "Epoch 4/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0475 - accuracy: 0.9876\n",
            "Epoch 5/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0302 - accuracy: 0.9908\n",
            "Epoch 6/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0277 - accuracy: 0.9908\n",
            "Epoch 7/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0166 - accuracy: 0.9940\n",
            "Epoch 8/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0195 - accuracy: 0.9946\n",
            "Epoch 9/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0186 - accuracy: 0.9945\n",
            "Epoch 10/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0142 - accuracy: 0.9967\n",
            "Epoch 11/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0134 - accuracy: 0.9965\n",
            "Epoch 12/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0056 - accuracy: 0.9987\n",
            "Epoch 13/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0089 - accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0069 - accuracy: 0.9975\n",
            "Epoch 15/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0109 - accuracy: 0.9956\n",
            "Epoch 16/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0094 - accuracy: 0.9978\n",
            "Epoch 17/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0051 - accuracy: 0.9984\n",
            "Epoch 18/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0147 - accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.9977\n",
            "Epoch 20/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0025 - accuracy: 0.9991\n",
            "Epoch 21/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0114 - accuracy: 0.9961\n",
            "Epoch 22/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0141 - accuracy: 0.9976\n",
            "Epoch 23/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0028 - accuracy: 0.9993\n",
            "Epoch 24/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "Epoch 25/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0111 - accuracy: 0.9970\n",
            "Epoch 26/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0061 - accuracy: 0.9993\n",
            "Epoch 27/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0049 - accuracy: 0.9994\n",
            "Epoch 28/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0057 - accuracy: 0.9991\n",
            "Epoch 29/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0025 - accuracy: 0.9994\n",
            "Epoch 30/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0099 - accuracy: 0.9966\n",
            "Epoch 31/100\n",
            "1056/1056 [==============================] - 2s 2ms/step - loss: 0.0027 - accuracy: 0.9991\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plKwa3xVWply",
        "outputId": "141b8e64-b7a2-4c59-f80b-2ca989e791ea"
      },
      "source": [
        "preds = model.predict(X_t_test_std)\n",
        "scores = model.evaluate(X_t_test_std, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83/83 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icc3KWDoXh7n",
        "outputId": "cde16577-efc0-4e10-9873-c2614c1068ff"
      },
      "source": [
        "preds.round()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdImRRboXzdB",
        "outputId": "0c4f8e03-7584-4d1b-b5bd-b1a86716cca9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test, preds.round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1263,   71],\n",
              "       [  29, 1277]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "pNCFOvVtjsFl",
        "outputId": "9afb5edd-95b0-454b-9962-7da70241f916"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_test,preds.round(),normalize='true'), annot=True);#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA9FuNkXRjSV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "45bbe1ad-7d3f-4a6f-c3d1-87362d379fe3"
      },
      "source": [
        "# Create function returning a compiled network\n",
        "def create_network():\n",
        "      model = keras.Sequential([\n",
        "      layers.Dense(100 , activation='relu', input_shape=[93]),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dropout(0.10),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-4eaabe570a59>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk3I3yJuUCcJ",
        "outputId": "7f3bf3ff-1e8c-4721-ebaa-c433d9fdfba3"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy\n",
        "\n",
        "early_stop =  EarlyStopping(monitor='loss',mode='max', verbose=1, patience=30,restore_best_weights=True)\n",
        "\n",
        "std_slc =  StandardScaler()\n",
        "std_slc.fit(data)\n",
        "data_std = std_slc.transform(data)\n",
        "pca = PCA(n_components=93)# adjust yourself\n",
        "pca.fit(data_std)\n",
        "data_std = pca.transform(data_std)\n",
        "\n",
        "# Wrap Keras model so it can be used by scikit-learn\n",
        "#neural_network = KerasClassifier(build_fn=create_network, epochs=1000, batch_size=100, verbose=1, callbacks=[early_stop])\n",
        "# Evaluate neural network using three-fold cross-validation\n",
        "#cross_val_score(neural_network, data_std, target, cv=10)\n",
        "seed = 7\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(data_std, target):\n",
        "  early_stop =  EarlyStopping(monitor='loss',mode='max', verbose=1, patience=30,restore_best_weights=True)\n",
        "  model = keras.Sequential([\n",
        "      layers.Dense(100 , activation='relu', input_shape=[93]),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dropout(0.10),\n",
        "      layers.Dense(100, activation='relu'),\n",
        "      layers.Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.fit(data_std[train], target[train], epochs=1000, batch_size=10, verbose=1, callbacks=[early_stop])\n",
        "\t# evaluate the model\n",
        "  scores = model.evaluate(data_std[test], target[test], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2841 - accuracy: 0.8925\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0932 - accuracy: 0.9686\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0737 - accuracy: 0.9814\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0450 - accuracy: 0.9869\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0296 - accuracy: 0.9910\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0214 - accuracy: 0.9925\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0187 - accuracy: 0.9944\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0166 - accuracy: 0.9947\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0089 - accuracy: 0.9973\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0114 - accuracy: 0.9966\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0131 - accuracy: 0.9966\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0064 - accuracy: 0.9984\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0025 - accuracy: 0.9996\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0183 - accuracy: 0.9954\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0057 - accuracy: 0.9975\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0109 - accuracy: 0.9973\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0118 - accuracy: 0.9962\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9997\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0141 - accuracy: 0.9958\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 3.0794e-04 - accuracy: 1.0000\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 1.0876e-04 - accuracy: 1.0000\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0436 - accuracy: 0.9924\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9988\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0221 - accuracy: 0.9974\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0056 - accuracy: 0.9982\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0065 - accuracy: 0.9989\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0039 - accuracy: 0.9991\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0131 - accuracy: 0.9956\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0020 - accuracy: 0.9991\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 6.8139e-04 - accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 95.45%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2862 - accuracy: 0.8934\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1042 - accuracy: 0.9652\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0629 - accuracy: 0.9798\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0367 - accuracy: 0.9879\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0236 - accuracy: 0.9927\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9928\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0150 - accuracy: 0.9957\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0151 - accuracy: 0.9959\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0135 - accuracy: 0.9973\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0211 - accuracy: 0.9926\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0072 - accuracy: 0.9983\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0229 - accuracy: 0.9950\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9992\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0089 - accuracy: 0.9980\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0101 - accuracy: 0.9960\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9989\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0111 - accuracy: 0.9968\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0128 - accuracy: 0.9962\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0051 - accuracy: 0.9982\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0114 - accuracy: 0.9954\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0054 - accuracy: 0.9985\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0065 - accuracy: 0.9976\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0061 - accuracy: 0.9984\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0037 - accuracy: 0.9994\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0169 - accuracy: 0.9973\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0072 - accuracy: 0.9992\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0069 - accuracy: 0.9980\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 6.2470e-04 - accuracy: 1.0000\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9988\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0058 - accuracy: 0.9988\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 95.98%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2716 - accuracy: 0.8952\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1026 - accuracy: 0.9679\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0566 - accuracy: 0.9827\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0336 - accuracy: 0.9909\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0259 - accuracy: 0.9914\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0213 - accuracy: 0.9935\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0147 - accuracy: 0.9958\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0143 - accuracy: 0.9958\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0163 - accuracy: 0.9937\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0106 - accuracy: 0.9972\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0128 - accuracy: 0.9959\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0109 - accuracy: 0.9975\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0075 - accuracy: 0.9981\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0050 - accuracy: 0.9986\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0096 - accuracy: 0.9970\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0062 - accuracy: 0.9984\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0091 - accuracy: 0.9984\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0132 - accuracy: 0.9965\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0060 - accuracy: 0.9979\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0115 - accuracy: 0.9985\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0137 - accuracy: 0.9983\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0060 - accuracy: 0.9976\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 8.0030e-04 - accuracy: 0.9999\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0046 - accuracy: 0.9989\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0095 - accuracy: 0.9976\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0054 - accuracy: 0.9984\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 8.7305e-04 - accuracy: 0.9997\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0133 - accuracy: 0.9965\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9986\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 1.0675e-04 - accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 95.68%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2641 - accuracy: 0.8979\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0918 - accuracy: 0.9709\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0565 - accuracy: 0.9827\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0348 - accuracy: 0.9898\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0277 - accuracy: 0.9911\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0180 - accuracy: 0.9945\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0150 - accuracy: 0.9949\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0205 - accuracy: 0.9941\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0051 - accuracy: 0.9987\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0143 - accuracy: 0.9956\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0079 - accuracy: 0.9976\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0157 - accuracy: 0.9960\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0065 - accuracy: 0.9982\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0083 - accuracy: 0.9977\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0056 - accuracy: 0.9986\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 0.9993\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0100 - accuracy: 0.9965\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0088 - accuracy: 0.9978\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0082 - accuracy: 0.9978\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9986\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0056 - accuracy: 0.9984\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0053 - accuracy: 0.9981\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0084 - accuracy: 0.9975\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0083 - accuracy: 0.9976\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0062 - accuracy: 0.9991\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 0.9997\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0049 - accuracy: 0.9988\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 95.30%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2680 - accuracy: 0.9042\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1053 - accuracy: 0.9652\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0662 - accuracy: 0.9795\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0456 - accuracy: 0.9861\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0268 - accuracy: 0.9922\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0296 - accuracy: 0.9894\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0247 - accuracy: 0.9928\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0154 - accuracy: 0.9949\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0122 - accuracy: 0.9970\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 2s 2ms/step - loss: 0.0142 - accuracy: 0.9960\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0067 - accuracy: 0.9975\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0065 - accuracy: 0.9983\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0078 - accuracy: 0.9970\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0097 - accuracy: 0.9971\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0172 - accuracy: 0.9957\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0102 - accuracy: 0.9965\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0061 - accuracy: 0.9982\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0100 - accuracy: 0.9967\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9978\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0119 - accuracy: 0.9970\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0049 - accuracy: 0.9988\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0108 - accuracy: 0.9980\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0098 - accuracy: 0.9970\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0037 - accuracy: 0.9990\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0067 - accuracy: 0.9983\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9987\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0068 - accuracy: 0.9982\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0090 - accuracy: 0.9992\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9990\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 97.27%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2736 - accuracy: 0.8869\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1000 - accuracy: 0.9697\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0592 - accuracy: 0.9827\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0474 - accuracy: 0.9871\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0275 - accuracy: 0.9922\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0303 - accuracy: 0.9917\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0400 - accuracy: 0.9940\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0073 - accuracy: 0.9983\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0148 - accuracy: 0.9959\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0137 - accuracy: 0.9951\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0145 - accuracy: 0.9957\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0091 - accuracy: 0.9973\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0069 - accuracy: 0.9984\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9975\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0125 - accuracy: 0.9971\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0073 - accuracy: 0.9975\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0080 - accuracy: 0.9984\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0085 - accuracy: 0.9976\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9969\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0061 - accuracy: 0.9980\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0070 - accuracy: 0.9982\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0098 - accuracy: 0.9986\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.9211e-04 - accuracy: 0.9999\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9981\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0087 - accuracy: 0.9977\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9993\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0063 - accuracy: 0.9981\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0068 - accuracy: 0.9983\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9995\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 96.06%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2681 - accuracy: 0.8964\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1026 - accuracy: 0.9661\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0703 - accuracy: 0.9787\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0452 - accuracy: 0.9855\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0415 - accuracy: 0.9875\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0218 - accuracy: 0.9939\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0225 - accuracy: 0.9932\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0148 - accuracy: 0.9950\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0103 - accuracy: 0.9976\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0196 - accuracy: 0.9937\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0130 - accuracy: 0.9967\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0110 - accuracy: 0.9975\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0210 - accuracy: 0.9975\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0140 - accuracy: 0.9957\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0138 - accuracy: 0.9963\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9988\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0271 - accuracy: 0.9971\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0071 - accuracy: 0.9981\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9988\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0079 - accuracy: 0.9985\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0052 - accuracy: 0.9985\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0053 - accuracy: 0.9980\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0090 - accuracy: 0.9970\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 0.9996\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0084 - accuracy: 0.9983\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 1.8123e-04 - accuracy: 1.0000\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9997\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9982\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0034 - accuracy: 0.9988\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 94.39%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2734 - accuracy: 0.8984\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0990 - accuracy: 0.9698\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0646 - accuracy: 0.9808\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0442 - accuracy: 0.9859\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0382 - accuracy: 0.9891\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0232 - accuracy: 0.9937\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0264 - accuracy: 0.9917\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0134 - accuracy: 0.9965\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0130 - accuracy: 0.9960\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0124 - accuracy: 0.9959\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0115 - accuracy: 0.9974\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0076 - accuracy: 0.9974\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0145 - accuracy: 0.9957\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0092 - accuracy: 0.9966\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0044 - accuracy: 0.9988\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0090 - accuracy: 0.9972\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0130 - accuracy: 0.9964\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0038 - accuracy: 0.9993\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0091 - accuracy: 0.9965\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0033 - accuracy: 0.9992\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9969\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9996\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0045 - accuracy: 0.9990\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9993\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0058 - accuracy: 0.9990\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0029 - accuracy: 0.9992\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0043 - accuracy: 0.9984\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 0.9993\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0091 - accuracy: 0.9977\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 95.76%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2775 - accuracy: 0.8930\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1020 - accuracy: 0.9685\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0648 - accuracy: 0.9810\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0450 - accuracy: 0.9889\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0260 - accuracy: 0.9914\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0302 - accuracy: 0.9911\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0139 - accuracy: 0.9957\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0149 - accuracy: 0.9960\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0174 - accuracy: 0.9957\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0195 - accuracy: 0.9942\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0069 - accuracy: 0.9979\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0089 - accuracy: 0.9971\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0084 - accuracy: 0.9973\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0104 - accuracy: 0.9969\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9984\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0087 - accuracy: 0.9975\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0175 - accuracy: 0.9947\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9998\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9989\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9985\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0068 - accuracy: 0.9989\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0119 - accuracy: 0.9969\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 9.9809e-04 - accuracy: 0.9996\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0071 - accuracy: 0.9988\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9991\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0094 - accuracy: 0.9977\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0074 - accuracy: 0.9986\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 0.9988\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 95.83%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2729 - accuracy: 0.8901\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1011 - accuracy: 0.9658\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0696 - accuracy: 0.9810\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0341 - accuracy: 0.9902\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0349 - accuracy: 0.9896\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0191 - accuracy: 0.9937\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0242 - accuracy: 0.9928\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0188 - accuracy: 0.9939\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0069 - accuracy: 0.9978\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0109 - accuracy: 0.9962\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0122 - accuracy: 0.9956\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0071 - accuracy: 0.9971\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0067 - accuracy: 0.9979\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0165 - accuracy: 0.9949\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0105 - accuracy: 0.9969\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0079 - accuracy: 0.9984\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9990\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0092 - accuracy: 0.9972\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9994\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0052 - accuracy: 0.9989\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 9.9051e-04 - accuracy: 0.9999\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0122 - accuracy: 0.9979\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0065 - accuracy: 0.9975\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0128 - accuracy: 0.9975\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0055 - accuracy: 0.9985\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0102 - accuracy: 0.9975\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9997\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0071 - accuracy: 0.9985\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 96.36%\n",
            "95.81% (+/- 0.70%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjiuHMgP1dJ6",
        "outputId": "e0cace64-0463-4e47-923a-1fb4905d4988"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from numpy import unique\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 8, activation=\"relu\", input_shape=(93,1)))\n",
        "model.add(MaxPooling1D())\n",
        "#model.add(Conv1D(32, 4, activation=\"relu\"))\n",
        "#model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(93, activation=\"relu\"))\n",
        "model.add(Dense(2,activation = 'relu'))\n",
        "model.compile(loss = 'binary_crossentropy', \n",
        "     optimizer = \"adam\",               \n",
        "              metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_16 (Conv1D)           (None, 86, 32)            288       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 43, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1376)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 93)                128061    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 2)                 188       \n",
            "=================================================================\n",
            "Total params: 128,537\n",
            "Trainable params: 128,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvwklXC7BbqJ"
      },
      "source": [
        "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
        "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zej_YqSCx-fs",
        "outputId": "7a480a57-1be2-47f2-fdbc-a592700dafc1"
      },
      "source": [
        "X_t_train_std = X_t_train_std.reshape(10558, 93, 1)\n",
        "early_stop =  EarlyStopping(monitor='loss',mode='max', verbose=1, patience=30,restore_best_weights=True)\n",
        "model.fit(X_t_train_std , y_train, batch_size=16,epochs=100, verbose=1)#callbacks=[early_stop]\n",
        "print(X_t_train_std.shape)\n",
        "acc = model.evaluate(X_t_train_std, y_train)\n",
        "print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.8424 - accuracy: 0.6477\n",
            "Epoch 2/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.7169 - accuracy: 0.6326\n",
            "Epoch 3/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.3313 - accuracy: 0.7185\n",
            "Epoch 4/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.8141 - accuracy: 0.6926\n",
            "Epoch 5/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.4805 - accuracy: 0.6194\n",
            "Epoch 6/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.3130 - accuracy: 0.6548\n",
            "Epoch 7/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.2209 - accuracy: 0.7087\n",
            "Epoch 8/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.2111 - accuracy: 0.7142\n",
            "Epoch 9/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.2522 - accuracy: 0.7871\n",
            "Epoch 10/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.1648 - accuracy: 0.8596\n",
            "Epoch 11/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.2257 - accuracy: 0.7324\n",
            "Epoch 12/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.1421 - accuracy: 0.7635\n",
            "Epoch 13/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.1581 - accuracy: 0.7262\n",
            "Epoch 14/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1171 - accuracy: 0.7393\n",
            "Epoch 15/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.1440 - accuracy: 0.7268\n",
            "Epoch 16/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1349 - accuracy: 0.6896\n",
            "Epoch 17/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.3112 - accuracy: 0.7086\n",
            "Epoch 18/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2384 - accuracy: 0.7300\n",
            "Epoch 19/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1487 - accuracy: 0.7453\n",
            "Epoch 20/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1373 - accuracy: 0.7898\n",
            "Epoch 21/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.4665 - accuracy: 0.8050\n",
            "Epoch 22/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.4731 - accuracy: 0.8955\n",
            "Epoch 23/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2654 - accuracy: 0.9033\n",
            "Epoch 24/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2009 - accuracy: 0.8901\n",
            "Epoch 25/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1785 - accuracy: 0.8966\n",
            "Epoch 26/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.3280 - accuracy: 0.8806\n",
            "Epoch 27/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1726 - accuracy: 0.8993\n",
            "Epoch 28/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2431 - accuracy: 0.8841\n",
            "Epoch 29/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.4387 - accuracy: 0.8525\n",
            "Epoch 30/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2740 - accuracy: 0.8502\n",
            "Epoch 31/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2766 - accuracy: 0.8526\n",
            "Epoch 32/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.2102 - accuracy: 0.9007\n",
            "Epoch 33/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1444 - accuracy: 0.9215\n",
            "Epoch 34/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0943 - accuracy: 0.9248\n",
            "Epoch 35/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.9443\n",
            "Epoch 36/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.9225\n",
            "Epoch 37/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0668 - accuracy: 0.9247\n",
            "Epoch 38/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1582 - accuracy: 0.8882\n",
            "Epoch 39/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1194 - accuracy: 0.7896\n",
            "Epoch 40/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8353\n",
            "Epoch 41/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2054 - accuracy: 0.7870\n",
            "Epoch 42/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1896 - accuracy: 0.8464\n",
            "Epoch 43/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1388 - accuracy: 0.8898\n",
            "Epoch 44/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0678 - accuracy: 0.8662\n",
            "Epoch 45/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0990 - accuracy: 0.9232\n",
            "Epoch 46/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1437 - accuracy: 0.8667\n",
            "Epoch 47/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2336 - accuracy: 0.8728\n",
            "Epoch 48/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1835 - accuracy: 0.9274\n",
            "Epoch 49/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2509 - accuracy: 0.8983\n",
            "Epoch 50/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2869 - accuracy: 0.8899\n",
            "Epoch 51/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.3269 - accuracy: 0.8499\n",
            "Epoch 52/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.6476 - accuracy: 0.8005\n",
            "Epoch 53/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.5248 - accuracy: 0.8705\n",
            "Epoch 54/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8037\n",
            "Epoch 55/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1865 - accuracy: 0.8515\n",
            "Epoch 56/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1611 - accuracy: 0.9095\n",
            "Epoch 57/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1936 - accuracy: 0.8893\n",
            "Epoch 58/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1188 - accuracy: 0.8643\n",
            "Epoch 59/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1000 - accuracy: 0.9026\n",
            "Epoch 60/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1025 - accuracy: 0.9173\n",
            "Epoch 61/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1231 - accuracy: 0.9096\n",
            "Epoch 62/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1301 - accuracy: 0.9103\n",
            "Epoch 63/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.2791 - accuracy: 0.8637\n",
            "Epoch 64/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1930 - accuracy: 0.7815\n",
            "Epoch 65/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0989 - accuracy: 0.8158\n",
            "Epoch 66/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0627 - accuracy: 0.8348\n",
            "Epoch 67/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1177 - accuracy: 0.8053\n",
            "Epoch 68/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.1053 - accuracy: 0.8398\n",
            "Epoch 69/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8670\n",
            "Epoch 70/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0690 - accuracy: 0.8341\n",
            "Epoch 71/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0661 - accuracy: 0.8857\n",
            "Epoch 72/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1912 - accuracy: 0.9255\n",
            "Epoch 73/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1652 - accuracy: 0.9011\n",
            "Epoch 74/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1516 - accuracy: 0.9419\n",
            "Epoch 75/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1311 - accuracy: 0.9583\n",
            "Epoch 76/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1147 - accuracy: 0.9665\n",
            "Epoch 77/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.9434\n",
            "Epoch 78/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0656 - accuracy: 0.9441\n",
            "Epoch 79/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1272 - accuracy: 0.9233\n",
            "Epoch 80/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1237 - accuracy: 0.9401\n",
            "Epoch 81/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.1175 - accuracy: 0.8304\n",
            "Epoch 82/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.8575\n",
            "Epoch 83/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.9147\n",
            "Epoch 84/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0657 - accuracy: 0.9095\n",
            "Epoch 85/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.0841 - accuracy: 0.8433\n",
            "Epoch 86/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0654 - accuracy: 0.9308\n",
            "Epoch 87/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0935 - accuracy: 0.9339\n",
            "Epoch 88/100\n",
            "660/660 [==============================] - 2s 3ms/step - loss: 0.1272 - accuracy: 0.9236\n",
            "Epoch 89/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8983\n",
            "Epoch 90/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0620 - accuracy: 0.8870\n",
            "Epoch 91/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0561 - accuracy: 0.9284\n",
            "Epoch 92/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1406 - accuracy: 0.8754\n",
            "Epoch 93/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1136 - accuracy: 0.8694\n",
            "Epoch 94/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0433 - accuracy: 0.8619\n",
            "Epoch 95/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1316 - accuracy: 0.8866\n",
            "Epoch 96/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0700 - accuracy: 0.9272\n",
            "Epoch 97/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.1032 - accuracy: 0.9265\n",
            "Epoch 98/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0907 - accuracy: 0.9380\n",
            "Epoch 99/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0543 - accuracy: 0.9559\n",
            "Epoch 100/100\n",
            "660/660 [==============================] - 2s 2ms/step - loss: 0.0442 - accuracy: 0.9392\n",
            "(10558, 93, 1)\n",
            "330/330 [==============================] - 1s 2ms/step - loss: 0.0441 - accuracy: 0.9375\n",
            "Loss: 0.04408039152622223  Accuracy: 0.9374881386756897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzOIkRS3x_H2",
        "outputId": "02c70955-71ee-4cfd-b259-5bb274630f7a"
      },
      "source": [
        "X_t_test_std = X_t_test_std.reshape(2640, 93, 1)\n",
        "\n",
        "pred = model.predict(X_t_test_std)\n",
        "pred_y = pred.argmax(axis=-1)\n",
        "print(pred_y)\n",
        "cm = confusion_matrix(y_test, pred_y)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 ... 0 1 0]\n",
            "[[1306   28]\n",
            " [ 149 1157]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q-Umo6PoVcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549a0d3a-e361-4f86-bc94-1c5fc8809f26"
      },
      "source": [
        "early_stop =  EarlyStopping(monitor='loss',mode='max', verbose=1, patience=30,restore_best_weights=True)\n",
        "std_slc =  StandardScaler()\n",
        "std_slc.fit(data)\n",
        "data_std = std_slc.transform(data)\n",
        "pca = PCA(n_components=93)# adjust yourself\n",
        "pca.fit(data_std)\n",
        "data_std = pca.transform(data_std)\n",
        "print(data_std.shape)\n",
        "data_std = data_std.reshape(13198, 93, 1)\n",
        "\n",
        "\n",
        "\n",
        "# Wrap Keras model so it can be used by scikit-learn\n",
        "#neural_network = KerasClassifier(build_fn=create_network, epochs=1000, batch_size=100, verbose=1, callbacks=[early_stop])\n",
        "# Evaluate neural network using three-fold cross-validation\n",
        "#cross_val_score(neural_network, data_std, target, cv=10)\n",
        "seed = 7\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(data_std, target):\n",
        "  early_stop =  EarlyStopping(monitor='loss',mode='max', verbose=1, patience=30,restore_best_weights=True)\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(32, 8, activation=\"relu\", input_shape=(93,1)))\n",
        "  model.add(MaxPooling1D())\n",
        "  #model.add(Conv1D(32, 4, activation=\"relu\"))\n",
        "  #model.add(MaxPooling1D())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(93, activation=\"relu\"))\n",
        "  model.add(Dense(2,activation = 'relu'))\n",
        "  model.compile(loss = 'binary_crossentropy', \n",
        "      optimizer = \"adam\",               \n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  model.fit(data_std[train], target[train], epochs=1000, batch_size=10, verbose=1, callbacks=[early_stop])\n",
        "\t# evaluate the model\n",
        "  scores = model.evaluate(data_std[test], target[test], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13198, 93)\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 2.9545 - accuracy: 0.5779\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.7542 - accuracy: 0.6252\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 4.0485 - accuracy: 0.8085\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6841 - accuracy: 0.5018\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7131 - accuracy: 0.5000\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.5952 - accuracy: 0.5076\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7232 - accuracy: 0.4993\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6985 - accuracy: 0.5009\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7035 - accuracy: 0.5006\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7185 - accuracy: 0.4996\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6488 - accuracy: 0.5041\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6380 - accuracy: 0.5048\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.8659 - accuracy: 0.4901\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7634 - accuracy: 0.4967\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6834 - accuracy: 0.5019\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7063 - accuracy: 0.5004\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.8064 - accuracy: 0.4939\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7191 - accuracy: 0.4996\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6464 - accuracy: 0.5043\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.8194 - accuracy: 0.4931\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.8129 - accuracy: 0.4935\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6426 - accuracy: 0.5045\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6191 - accuracy: 0.5061\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.8176 - accuracy: 0.4932\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7760 - accuracy: 0.4959\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7705 - accuracy: 0.4962\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7108 - accuracy: 0.5001\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6735 - accuracy: 0.5025\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.8505 - accuracy: 0.4911\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7186 - accuracy: 0.4996\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7042 - accuracy: 0.5005\n",
            "Epoch 32/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6720 - accuracy: 0.5026\n",
            "Epoch 33/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7826 - accuracy: 0.4955\n",
            "Epoch 34/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7553 - accuracy: 0.4972\n",
            "Epoch 35/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6633 - accuracy: 0.5032\n",
            "Epoch 36/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.5730 - accuracy: 0.5090\n",
            "Epoch 37/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7166 - accuracy: 0.4997\n",
            "Epoch 38/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7459 - accuracy: 0.4978\n",
            "Epoch 39/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7404 - accuracy: 0.4982\n",
            "Epoch 40/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7461 - accuracy: 0.4978\n",
            "Epoch 41/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7007 - accuracy: 0.5008\n",
            "Epoch 42/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6299 - accuracy: 0.5054\n",
            "Epoch 43/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7754 - accuracy: 0.4959\n",
            "Epoch 44/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.6374 - accuracy: 0.5049\n",
            "Epoch 45/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7566 - accuracy: 0.4971\n",
            "Epoch 46/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.9274 - accuracy: 0.4861\n",
            "Epoch 47/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7120 - accuracy: 0.5000\n",
            "Epoch 48/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7638 - accuracy: 0.4967\n",
            "Epoch 49/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 7.7620 - accuracy: 0.4968\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00049: early stopping\n",
            "accuracy: 50.00%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.9387 - accuracy: 0.5978\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.6082 - accuracy: 0.6486\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3749 - accuracy: 0.5760\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2441 - accuracy: 0.8276\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.4062 - accuracy: 0.7679\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.5740 - accuracy: 0.6172\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3704 - accuracy: 0.7030\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.7508 - accuracy: 0.6271\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1969 - accuracy: 0.7184\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1646 - accuracy: 0.7324\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2593 - accuracy: 0.7591\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3149 - accuracy: 0.8831\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1378 - accuracy: 0.8838\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2170 - accuracy: 0.9059\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1760 - accuracy: 0.8959\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1538 - accuracy: 0.8929\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.7794 - accuracy: 0.8009\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3867 - accuracy: 0.7878\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1318 - accuracy: 0.8150\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2589 - accuracy: 0.7971\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.4188 - accuracy: 0.5505\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3362 - accuracy: 0.7060\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3313 - accuracy: 0.7704\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.4273 - accuracy: 0.8288\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3026 - accuracy: 0.7790\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1726 - accuracy: 0.7732\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1707 - accuracy: 0.8209\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3716 - accuracy: 0.7608\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.5005 - accuracy: 0.7994\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1646 - accuracy: 0.8487\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1706 - accuracy: 0.8785\n",
            "Epoch 32/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3301 - accuracy: 0.7900\n",
            "Epoch 33/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2382 - accuracy: 0.8056\n",
            "Epoch 34/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.0897 - accuracy: 0.8364\n",
            "Epoch 35/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1160 - accuracy: 0.8372\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00035: early stopping\n",
            "accuracy: 53.26%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.7833 - accuracy: 0.5547\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4198 - accuracy: 0.6036\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.5127 - accuracy: 0.6105\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2747 - accuracy: 0.6837\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.4387 - accuracy: 0.6164\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2837 - accuracy: 0.6171\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.4795 - accuracy: 0.6171\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.5652 - accuracy: 0.7972\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2586 - accuracy: 0.8377\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3594 - accuracy: 0.8260\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.6065 - accuracy: 0.8646\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.4432 - accuracy: 0.8633\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.4576 - accuracy: 0.8532\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.9864 - accuracy: 0.8890\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 1.0076 - accuracy: 0.8484\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.9223 - accuracy: 0.8661\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.5623 - accuracy: 0.8380\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3410 - accuracy: 0.8054\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2757 - accuracy: 0.8681\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2059 - accuracy: 0.8909\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2890 - accuracy: 0.8927\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3802 - accuracy: 0.6558\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2227 - accuracy: 0.7971\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.6910 - accuracy: 0.7721\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.8285 - accuracy: 0.7566\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 1.1331 - accuracy: 0.8387\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3759 - accuracy: 0.8690\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3374 - accuracy: 0.7991\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2176 - accuracy: 0.8529\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.5086 - accuracy: 0.9007\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1836 - accuracy: 0.9169\n",
            "Epoch 32/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1521 - accuracy: 0.9135\n",
            "Epoch 33/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1958 - accuracy: 0.9105\n",
            "Epoch 34/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2201 - accuracy: 0.8582\n",
            "Epoch 35/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3709 - accuracy: 0.8222\n",
            "Epoch 36/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.3523 - accuracy: 0.8205\n",
            "Epoch 37/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.4155 - accuracy: 0.8679\n",
            "Epoch 38/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3423 - accuracy: 0.5966\n",
            "Epoch 39/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4356 - accuracy: 0.8668\n",
            "Epoch 40/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2007 - accuracy: 0.6994\n",
            "Epoch 41/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1557 - accuracy: 0.7806\n",
            "Epoch 42/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1859 - accuracy: 0.8029\n",
            "Epoch 43/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1697 - accuracy: 0.7163\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00043: early stopping\n",
            "accuracy: 88.56%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 4.3415 - accuracy: 0.4982\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 4.1495 - accuracy: 0.4959\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 4.3770 - accuracy: 0.4997\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 4.0883 - accuracy: 0.5095\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 4.0177 - accuracy: 0.5024\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 4.1689 - accuracy: 0.4955\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 4.0872 - accuracy: 0.5040\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 4.1766 - accuracy: 0.4951\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 3.0437 - accuracy: 0.5418\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.9049 - accuracy: 0.7205\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.7240 - accuracy: 0.6134\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.7498 - accuracy: 0.5571\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4473 - accuracy: 0.5278\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6146 - accuracy: 0.5216\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3044 - accuracy: 0.5473\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5339 - accuracy: 0.6473\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4321 - accuracy: 0.6964\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3705 - accuracy: 0.6009\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1790 - accuracy: 0.6276\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4572 - accuracy: 0.6697\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5120 - accuracy: 0.5823\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3716 - accuracy: 0.7113\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1796 - accuracy: 0.5823\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1526 - accuracy: 0.6477\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2861 - accuracy: 0.5536\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1954 - accuracy: 0.5868\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1660 - accuracy: 0.5817\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1296 - accuracy: 0.6271\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0968 - accuracy: 0.6890\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1120 - accuracy: 0.7495\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1787 - accuracy: 0.6967\n",
            "Epoch 32/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.1561 - accuracy: 0.7259\n",
            "Epoch 33/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.2429 - accuracy: 0.6782\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00033: early stopping\n",
            "accuracy: 50.00%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.9324 - accuracy: 0.4770\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4765 - accuracy: 0.6341\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3536 - accuracy: 0.5769\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3696 - accuracy: 0.7743\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4500 - accuracy: 0.8179\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2854 - accuracy: 0.7987\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2507 - accuracy: 0.8151\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 2ms/step - loss: 0.9858 - accuracy: 0.7525\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3040 - accuracy: 0.8046\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3058 - accuracy: 0.7629\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2509 - accuracy: 0.7953\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1542 - accuracy: 0.7632\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1178 - accuracy: 0.7934\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2317 - accuracy: 0.7659\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1732 - accuracy: 0.7585\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1964 - accuracy: 0.8749\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1110 - accuracy: 0.8262\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1194 - accuracy: 0.8121\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5159 - accuracy: 0.8189\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2931 - accuracy: 0.8477\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3149 - accuracy: 0.8249\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2404 - accuracy: 0.7410\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1925 - accuracy: 0.7123\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0911 - accuracy: 0.7712\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0771 - accuracy: 0.7491\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1310 - accuracy: 0.7618\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3075 - accuracy: 0.8404\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2490 - accuracy: 0.8171\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2477 - accuracy: 0.7571\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0935 - accuracy: 0.8361\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0979 - accuracy: 0.7430\n",
            "Epoch 32/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0876 - accuracy: 0.8657\n",
            "Epoch 33/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0860 - accuracy: 0.8635\n",
            "Epoch 34/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0523 - accuracy: 0.8586\n",
            "Epoch 35/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1508 - accuracy: 0.8761\n",
            "Epoch 36/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0985 - accuracy: 0.9044\n",
            "Epoch 37/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1459 - accuracy: 0.9073\n",
            "Epoch 38/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2048 - accuracy: 0.8485\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00038: early stopping\n",
            "accuracy: 84.09%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.8507 - accuracy: 0.5666\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.8468 - accuracy: 0.7228\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3600 - accuracy: 0.7345\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3938 - accuracy: 0.7948\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4431 - accuracy: 0.6751\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5979 - accuracy: 0.5032\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4138 - accuracy: 0.6394\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4566 - accuracy: 0.6853\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5095 - accuracy: 0.6867\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6654 - accuracy: 0.7237\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3622 - accuracy: 0.6900\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.8793 - accuracy: 0.7474\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5254 - accuracy: 0.5628\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3635 - accuracy: 0.6382\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4430 - accuracy: 0.6875\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 1.0018 - accuracy: 0.7031\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5494 - accuracy: 0.6929\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2978 - accuracy: 0.7423\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5334 - accuracy: 0.7150\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5315 - accuracy: 0.7735\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.8173 - accuracy: 0.7564\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4562 - accuracy: 0.7690\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3236 - accuracy: 0.7987\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2208 - accuracy: 0.8076\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1853 - accuracy: 0.8310\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1755 - accuracy: 0.7859\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3176 - accuracy: 0.7026\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1742 - accuracy: 0.8265\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2142 - accuracy: 0.7571\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2123 - accuracy: 0.8227\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4241 - accuracy: 0.7937\n",
            "Epoch 32/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2570 - accuracy: 0.8062\n",
            "Epoch 33/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2047 - accuracy: 0.7419\n",
            "Epoch 34/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4234 - accuracy: 0.7349\n",
            "Epoch 35/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1633 - accuracy: 0.8490\n",
            "Epoch 36/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3760 - accuracy: 0.7869\n",
            "Epoch 37/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2282 - accuracy: 0.7834\n",
            "Epoch 38/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1849 - accuracy: 0.7857\n",
            "Epoch 39/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3076 - accuracy: 0.6624\n",
            "Epoch 40/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2247 - accuracy: 0.8353\n",
            "Epoch 41/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2243 - accuracy: 0.7943\n",
            "Epoch 42/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1043 - accuracy: 0.7937\n",
            "Epoch 43/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1001 - accuracy: 0.8050\n",
            "Epoch 44/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0762 - accuracy: 0.8805\n",
            "Epoch 45/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1076 - accuracy: 0.8020\n",
            "Epoch 46/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0731 - accuracy: 0.8754\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00046: early stopping\n",
            "accuracy: 71.59%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.8884 - accuracy: 0.6413\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6089 - accuracy: 0.7521\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6037 - accuracy: 0.7127\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4648 - accuracy: 0.7936\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2708 - accuracy: 0.7887\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1719 - accuracy: 0.8629\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.8359\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2734 - accuracy: 0.7880\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1908 - accuracy: 0.7604\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2506 - accuracy: 0.6889\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1693 - accuracy: 0.7517\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1546 - accuracy: 0.7209\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1239 - accuracy: 0.7379\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2330 - accuracy: 0.7050\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1832 - accuracy: 0.7018\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1601 - accuracy: 0.6877\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.7561 - accuracy: 0.6011\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3270 - accuracy: 0.5822\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5351 - accuracy: 0.7383\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5973 - accuracy: 0.7209\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4291 - accuracy: 0.8124\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2394 - accuracy: 0.7191\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2503 - accuracy: 0.7999\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2438 - accuracy: 0.7467\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6293 - accuracy: 0.8019\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1434 - accuracy: 0.6759\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2837 - accuracy: 0.6941\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1671 - accuracy: 0.6175\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6150 - accuracy: 0.6747\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5547 - accuracy: 0.5266\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2580 - accuracy: 0.5725\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 56.36%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.7878 - accuracy: 0.6085\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4782 - accuracy: 0.6029\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3053 - accuracy: 0.6080\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3550 - accuracy: 0.5838\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3539 - accuracy: 0.6396\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5643 - accuracy: 0.7100\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5346 - accuracy: 0.6882\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4900 - accuracy: 0.7713\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4539 - accuracy: 0.5688\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6665 - accuracy: 0.5398\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 1.0064 - accuracy: 0.5129\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5383 - accuracy: 0.7042\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6781 - accuracy: 0.6902\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.7744 - accuracy: 0.5468\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3273 - accuracy: 0.5206\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2919 - accuracy: 0.5517\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3547 - accuracy: 0.6137\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.7816 - accuracy: 0.6126\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4091 - accuracy: 0.7078\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.8301 - accuracy: 0.7275\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5205 - accuracy: 0.5989\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2975 - accuracy: 0.6790\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2220 - accuracy: 0.6289\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6721 - accuracy: 0.6011\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4071 - accuracy: 0.6091\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4929 - accuracy: 0.6770\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2873 - accuracy: 0.6318\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2655 - accuracy: 0.6931\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1819 - accuracy: 0.6712\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1373 - accuracy: 0.6554\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2169 - accuracy: 0.5950\n",
            "Epoch 32/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2358 - accuracy: 0.5700\n",
            "Epoch 33/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2261 - accuracy: 0.5826\n",
            "Epoch 34/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1315 - accuracy: 0.5330\n",
            "Epoch 35/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0949 - accuracy: 0.5524\n",
            "Epoch 36/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1142 - accuracy: 0.6383\n",
            "Epoch 37/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1380 - accuracy: 0.5995\n",
            "Epoch 38/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3474 - accuracy: 0.7065\n",
            "Epoch 39/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2158 - accuracy: 0.5912\n",
            "Epoch 40/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.5459\n",
            "Epoch 41/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1110 - accuracy: 0.5687\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00041: early stopping\n",
            "accuracy: 67.27%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 4s 3ms/step - loss: 7.6396 - accuracy: 0.5041\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6700 - accuracy: 0.5098\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6692 - accuracy: 0.4936\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6699 - accuracy: 0.4971\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6688 - accuracy: 0.4896\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6693 - accuracy: 0.4994\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6688 - accuracy: 0.5015\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6688 - accuracy: 0.4949\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6690 - accuracy: 0.4965\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6687 - accuracy: 0.4984\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6690 - accuracy: 0.5043\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6688 - accuracy: 0.4979\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6680 - accuracy: 0.4879\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6686 - accuracy: 0.4994\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6691 - accuracy: 0.5016\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6721 - accuracy: 0.5051\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6701 - accuracy: 0.5020\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6694 - accuracy: 0.5052\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6688 - accuracy: 0.5004\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6683 - accuracy: 0.4943\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6686 - accuracy: 0.4991\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6679 - accuracy: 0.4923\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6679 - accuracy: 0.4929\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6707 - accuracy: 0.4962\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6695 - accuracy: 0.5088\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6696 - accuracy: 0.5036\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6688 - accuracy: 0.4999\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6683 - accuracy: 0.4950\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6686 - accuracy: 0.5004\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6694 - accuracy: 0.4994\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6690 - accuracy: 0.4988\n",
            "Epoch 32/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6686 - accuracy: 0.4981\n",
            "Epoch 33/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6697 - accuracy: 0.5045\n",
            "Epoch 34/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6693 - accuracy: 0.5066\n",
            "Epoch 35/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6682 - accuracy: 0.4935\n",
            "Epoch 36/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6684 - accuracy: 0.4980\n",
            "Epoch 37/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6720 - accuracy: 0.4970\n",
            "Epoch 38/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6701 - accuracy: 0.5065\n",
            "Epoch 39/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6687 - accuracy: 0.5000\n",
            "Epoch 40/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6696 - accuracy: 0.5011\n",
            "Epoch 41/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6684 - accuracy: 0.4969\n",
            "Epoch 42/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6684 - accuracy: 0.4971\n",
            "Epoch 43/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6698 - accuracy: 0.4976\n",
            "Epoch 44/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6691 - accuracy: 0.5020\n",
            "Epoch 45/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6700 - accuracy: 0.5040\n",
            "Epoch 46/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6695 - accuracy: 0.5060\n",
            "Epoch 47/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6689 - accuracy: 0.5011\n",
            "Epoch 48/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6696 - accuracy: 0.4969\n",
            "Epoch 49/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6689 - accuracy: 0.4982\n",
            "Epoch 50/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6687 - accuracy: 0.5012\n",
            "Epoch 51/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6691 - accuracy: 0.5025\n",
            "Epoch 52/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 7.6690 - accuracy: 0.5036\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00052: early stopping\n",
            "accuracy: 50.04%\n",
            "Epoch 1/1000\n",
            "1188/1188 [==============================] - 4s 3ms/step - loss: 0.8863 - accuracy: 0.5043\n",
            "Epoch 2/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3920 - accuracy: 0.5854\n",
            "Epoch 3/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5537 - accuracy: 0.4833\n",
            "Epoch 4/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3676 - accuracy: 0.5450\n",
            "Epoch 5/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2419 - accuracy: 0.6431\n",
            "Epoch 6/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3591 - accuracy: 0.6846\n",
            "Epoch 7/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2957 - accuracy: 0.8026\n",
            "Epoch 8/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1993 - accuracy: 0.7723\n",
            "Epoch 9/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1995 - accuracy: 0.7915\n",
            "Epoch 10/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.4077 - accuracy: 0.7416\n",
            "Epoch 11/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1306 - accuracy: 0.7836\n",
            "Epoch 12/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3897 - accuracy: 0.6425\n",
            "Epoch 13/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3545 - accuracy: 0.6639\n",
            "Epoch 14/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2287 - accuracy: 0.6663\n",
            "Epoch 15/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1386 - accuracy: 0.6596\n",
            "Epoch 16/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3942 - accuracy: 0.5762\n",
            "Epoch 17/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5411 - accuracy: 0.5898\n",
            "Epoch 18/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3095 - accuracy: 0.7260\n",
            "Epoch 19/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.6611 - accuracy: 0.7265\n",
            "Epoch 20/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2561 - accuracy: 0.7240\n",
            "Epoch 21/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.5352 - accuracy: 0.5278\n",
            "Epoch 22/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2729 - accuracy: 0.7495\n",
            "Epoch 23/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.3983 - accuracy: 0.5556\n",
            "Epoch 24/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2367 - accuracy: 0.7226\n",
            "Epoch 25/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2532 - accuracy: 0.7392\n",
            "Epoch 26/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1591 - accuracy: 0.6926\n",
            "Epoch 27/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1595 - accuracy: 0.7681\n",
            "Epoch 28/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1568 - accuracy: 0.6945\n",
            "Epoch 29/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1428 - accuracy: 0.7243\n",
            "Epoch 30/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.1514 - accuracy: 0.7115\n",
            "Epoch 31/1000\n",
            "1188/1188 [==============================] - 3s 3ms/step - loss: 0.2442 - accuracy: 0.6227\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "accuracy: 60.65%\n",
            "63.18% (+/- 13.57%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG6ki_M3QhJx",
        "outputId": "221277c0-7af6-408a-84e4-3426b8b555bd"
      },
      "source": [
        "n_neighbors = 1\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "data,target = SMOTE_oversample.fit_resample(data,target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=42)\n",
        "\"\"\"\n",
        "sns.set_style('white');\n",
        "sns.set_context(context='notebook',font_scale=1.2)\n",
        "sns.countplot(x=y_train);\n",
        "plt.title('Target variable balanced');\n",
        "\"\"\"\n",
        "std_slc =  StandardScaler()\n",
        "std_slc.fit(X_train)\n",
        "X_train_std = std_slc.transform(X_train)\n",
        "X_test_std = std_slc.transform(X_test)\n",
        "pca = PCA(n_components=93)# adjust yourself\n",
        "pca.fit(X_train_std)\n",
        "X_t_train_std = pca.transform(X_train_std)\n",
        "X_t_test_std = pca.transform(X_test_std)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors)\n",
        "knn.fit(X_t_train_std, y_train)\n",
        "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
        "     .format(knn.score(X_t_train_std, y_train)))\n",
        "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
        "     .format(knn.score(X_t_test_std, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of K-NN classifier on training set: 1.00\n",
            "Accuracy of K-NN classifier on test set: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB0AvLZPRsHw",
        "outputId": "e646c139-1b93-4033-e7da-7e9730bf7d3c"
      },
      "source": [
        "pred = knn.predict(X_t_test_std)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1245   89]\n",
            " [   2 1304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96      1334\n",
            "           1       0.94      1.00      0.97      1306\n",
            "\n",
            "    accuracy                           0.97      2640\n",
            "   macro avg       0.97      0.97      0.97      2640\n",
            "weighted avg       0.97      0.97      0.97      2640\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHanEHIljUtk",
        "outputId": "a5dc21de-542f-410b-f52d-8f009f178c84"
      },
      "source": [
        "#from sklearn.cross_validation import cross_val_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "std_slc =  StandardScaler()\n",
        "std_slc.fit(data)\n",
        "data_std = std_slc.transform(data)\n",
        "pca = PCA(n_components=93)# adjust yourself\n",
        "pca.fit(data_std)\n",
        "data_std = pca.transform(data_std)\n",
        "scores = cross_val_score(knn, data_std, target, cv=10, scoring='accuracy')\n",
        "print(scores)\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.93863636 0.96590909 0.95       0.93560606 0.97575758 0.98333333\n",
            " 0.97045455 0.975      0.9818044  0.97194845]\n",
            "0.9648449812759896\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}